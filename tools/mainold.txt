package main

import (
	"bufio"
	"encoding/xml"
	"fmt"
	"html/template"
	"log"
	"os"
	"path/filepath"
	"strings"

	"github.com/celsoRodrigues/cloop/model"
	"github.com/nguyenthenguyen/docx"
)

//Campaign to be exported
type campaign struct {
	Title string
	Body  string
	Cta   string
}

type linkStruct struct {
	URL  string
	Copy string
}

type marketing struct {
	Week      string
	Campaigns []campaign
	Links     []linkStruct
}

// SplitAt returns a bufio.SplitFunc closure, splitting at a substring
// scanner.Split(SplitAt("\n# "))
func SplitAt(substring string) func(data []byte, atEOF bool) (advance int, token []byte, err error) {

	return func(data []byte, atEOF bool) (advance int, token []byte, err error) {

		// Return nothing if at end of file and no data passed
		if atEOF && len(data) == 0 {
			return 0, nil, nil
		}

		// Find the index of the input of the separator substring
		if i := strings.Index(string(data), substring); i >= 0 {
			return i + len(substring), data[0:i], nil
		}

		// If at end of file with data return the data
		if atEOF {
			return len(data), data, nil
		}

		return
	}
}

//AddDash to be exported
func AddDash(s string) (sss string) {
	scanner := bufio.NewScanner(strings.NewReader(strings.Trim(s, " ")))
	scanner.Split(bufio.ScanWords)
	var ss string
	for scanner.Scan() {
		ss += scanner.Text() + "-"
	}
	return ss[0 : len(ss)-1]
}

//RemoveSpecial to be exported
func RemoveSpecial(s string) (sss string) {

	scanner := bufio.NewScanner(strings.NewReader(strings.Trim(s, " ")))
	scanner.Split(bufio.ScanRunes)
	var ss string
	for scanner.Scan() {
		if scanner.Text() != "!" || scanner.Text() != "?" || scanner.Text() != "'" || scanner.Text() != "." || scanner.Text() != ";" || scanner.Text() != "," || scanner.Text() != "Â£" {
			ss += scanner.Text()
		}

	}

	return ss
}

//Xplode to be exported
func Xplode(s string) (sss []string) {
	scanner := bufio.NewScanner(strings.NewReader(strings.Trim(s, " ")))
	scanner.Split(bufio.ScanWords)
	var ss []string

	for scanner.Scan() {
		ss = append(ss, scanner.Text())
	}
	return ss
}

//XplodeLast to be exported
func XplodeLast(s string) (sss []string) {
	scanner := bufio.NewScanner(strings.NewReader(strings.Trim(s, " ")))
	scanner.Split(bufio.ScanWords)
	var ss []string

	for scanner.Scan() {
		ss = append(ss, scanner.Text())
	}
	s1 := strings.Join(ss[:len(ss)-1], " ")
	s2 := strings.Join(ss[len(ss)-1:], " ")

	s3 := []string{s1, s2}
	return s3
}

//XplodeCta to be exported
func XplodeCta(s string) (sss []string) {
	scanner := bufio.NewScanner(strings.NewReader(strings.Trim(s, " ")))
	scanner.Split(SplitAt(","))
	var ss []string

	for scanner.Scan() {
		ss = append(ss, scanner.Text())
	}
	return ss
}

var fn = template.FuncMap{
	"AddDash":       AddDash,
	"Xplode":        Xplode,
	"XplodeLast":    XplodeLast,
	"XplodeCta":     XplodeCta,
	"RemoveSpecial": RemoveSpecial,
}

//init initializing, creating folders, if not there
func init() {

	var x = []string{
		"layout",
		"docx",
		"bin",
	}

	for _, i := range x {
		if _, err := os.Stat(i); os.IsNotExist(err) {
			os.Mkdir(i, 0755)
		}
	}

}

func main1() {

	r, err := docx.ReadDocxFile(filepath.Join("./docx", "hp2.docx"))
	defer r.Close()

	if err != nil {
		panic(err)
	}

	//fmt.Println(r.Content)

	mydoc := model.Document{}

	err = xml.Unmarshal([]byte(r.Content), &mydoc)
	if err != nil {
		fmt.Print(err)
		os.Exit(1)
	}

	for i := 0; i <= len(mydoc.Body.P)-1; i++ {

		if mydoc.Body.P[i].Sdt.SdtPr.Tag.Val == "name" {
			fmt.Printf("%s: ", mydoc.Body.P[i].Sdt.SdtPr.Tag.Val)
			fmt.Printf("%s\n", mydoc.Body.P[i].Sdt.SdtContent.R)
		}

	}

	//
	//mycapaign := campaign{}
	//link := linkStruct{}
	//
	//var cr = regexp.MustCompile(`</w:p>`)
	//var re = regexp.MustCompile(`[<][^>]*[>]`)
	//
	//str := cr.ReplaceAll([]byte(r.Content), []byte("\n"))
	//str = re.ReplaceAll([]byte(str), []byte(""))
	//fmt.Print(string(str))
	//scanner := bufio.NewScanner(strings.NewReader(string(str)))
	//
	//var week string
	//var links []string
	//var linksCopyLines []string
	//var titleLines []string
	//var bodyLines []string
	//var ctaLines []string
	//
	//for scanner.Scan() {
	//
	//	if strings.Contains(scanner.Text(), "Week:") {
	//		index := strings.Index(scanner.Text(), ":")
	//		week = strings.Trim(scanner.Text()[index+1:], " ")
	//	}
	//
	//	if strings.Contains(scanner.Text(), "Top Link:") {
	//		index := strings.Index(scanner.Text(), ":")
	//		link := strings.Trim(scanner.Text()[index+31:], " ")
	//		links = append(links, link)
	//	}
	//
	//	if strings.Contains(scanner.Text(), "Top Copy") {
	//		scanner.Scan()
	//		linksCopyLines = append(linksCopyLines, scanner.Text())
	//	}
	//
	//	if strings.Contains(scanner.Text(), "Title copy") {
	//		scanner.Scan()
	//		titleLines = append(titleLines, scanner.Text())
	//	}
	//
	//	if strings.Contains(scanner.Text(), "Body copy") {
	//		scanner.Scan()
	//		bodyLines = append(bodyLines, scanner.Text())
	//	}
	//
	//	if strings.Contains(scanner.Text(), "CTA copy") {
	//		var s string
	//		for {
	//			scanner.Scan()
	//			if len(scanner.Text()) == 0 {
	//				break
	//			}
	//			s += scanner.Text() + ", "
	//		}
	//		ctaLines = append(ctaLines, strings.Trim(s, ", "))
	//	}
	//}

	//if len(titleLines) != len(bodyLines) || len(ctaLines) != len(titleLines) || len(bodyLines) != len(ctaLines) {
	//	fmt.Println("There is a field(s) missing in the page\n You have:\n titles:", len(titleLines), "Bodies:", len(bodyLines), "Cta's:", len(ctaLines))
	//	os.Exit(1)
	//}
	//
	//if len(links) != len(linksCopyLines) {
	//	fmt.Println("There is a field(s) missing in the page\n You have:\n links:", len(links), "\n linkCopy:", len(linksCopyLines))
	//	os.Exit(1)
	//}
	//
	//var mycampaigns []campaign
	//var myLinks []linkStruct
	//for i := 0; i < len(titleLines); i++ {
	//
	//	mycapaign.Title = titleLines[i]
	//	mycapaign.Body = bodyLines[i]
	//	mycapaign.Cta = ctaLines[i]
	//
	//	mycampaigns = append(mycampaigns, mycapaign)
	//
	//}
	//
	//for i := 0; i < len(links); i++ {
	//
	//	link.URL = links[i]
	//	link.Copy = linksCopyLines[i]
	//
	//	myLinks = append(myLinks, link)
	//
	//}
	//
	//mkt := marketing{
	//	Week:      week,
	//	Campaigns: mycampaigns,
	//	Links:     myLinks,
	//}

	fd, err := os.OpenFile(filepath.Join("./bin", "page.html"), os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0755)
	defer fd.Close()

	tmpl := template.Must(template.New("layout.html").Funcs(fn).ParseFiles(filepath.Join("./layout", "layout.html")))
	err = tmpl.Execute(fd, mkt)
	if err != nil {
		log.Fatal(err)
	}

}
